---
title: "p8015_hw6_ax2173"
output: github_document
---

```{r}  
library(tidyverse)
library(modelr)
library(viridis)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = '90%'
)

theme_set(theme_classic() + theme(legend.position = 'bottom'))

options(
  ggplot2.continous.colour = 'viridis_d',
  ggplot2.continous.fill = 'viridis_d'
)

scalr_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

## Problem 1

To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 

## Problem 2

Import the data, and do some initial data manipulations, described as following:

* Create a city_state variable
* Create a binary variable indicating whether the homicide is solved. (1 represents solved, 0 represents unsolved)
* Omit several cities
* Limit analysis those for whom victim_race is white or black
* Change the type of victim_age to numeric

```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, ', ',state),
    whether_solve = ifelse(str_detect(disposition, 'Close'), 1, 0)
  ) %>% 
  select(-city, -state, -disposition) %>% 
  filter(
    !city_state %in% c('Dallas, TX', 'Phoenix, AZ','Kansas City, MO','Tulsa, AL'),
    victim_race %in% c('White','Black')
    ) %>% 
  filter(victim_age != 'Unknown') %>% 
  mutate(victim_age = as.numeric(victim_age))
```

For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. Save the output of glm as an R object, and apply the broom::tidy to this object.

```{r}
homicide_Bal_df = 
  homicide_df %>% 
  filter(city_state == 'Baltimore, MD') 

Bal_glm = 
  glm(whether_solve ~ victim_age + victim_sex + victim_race, family = binomial(link = logit), data = homicide_Bal_df) %>% 
  broom::tidy()
```

As for solving homicides comparing male victims to female victims keeping all other variables fixed, we can get these two things:

 * The estimated odds ratio is `r round(exp(Bal_glm$estimate[[3]]),3)`
 * The 95% confidence interval is (`r round(exp(Bal_glm$estimate[[3]]-1.96*Bal_glm$std.error[[3]]),3)`,`r round(exp(Bal_glm$estimate[[3]]+1.96*Bal_glm$std.error[[3]]),3)`)


Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. 

```{r}
homicide_df_models = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = purrr::map(.x = data, ~glm(whether_solve ~ victim_age + victim_sex + victim_race, family = binomial(link = logit), data = .x)),
    result = purrr::map(models, broom::tidy)
    ) %>% 
  select(-data, -models) %>% 
  unnest(result) %>% 
  filter(term == 'victim_sexMale') %>% 
  mutate(
    odds_estimate = exp(estimate),
    CI_lowerbond = exp(estimate - 1.96 * std.error),
    CI_upperbond = exp(estimate + 1.96 * std.error),
  ) %>% 
  select(city_state, estimate, CI_lowerbond, CI_upperbond) 

homicide_df_models %>% knitr::kable(digits = 3)
```

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r fig.width=9, fig.height=6}
homicide_df_models %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(city_state, estimate, color = city_state)) +
  geom_linerange(aes(ymin = CI_lowerbond, ymax = CI_upperbond)) +
  geom_errorbar(aes(ymin = CI_lowerbond, ymax = CI_upperbond), width = 0.8) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5)) +
  theme(legend.position = 'none') +
  labs(
    title = 'The Estimated ORs and CIs for Each City',
    x = 'Cities and states',
    y = 'Estimated ORs and CIs',
    caption = 'UNI: ax2173'
  )
```

Comments on this plot:

* The lowest estimated OR goes to New York, NY
* The highest estimated OR goes to Fresno, CA
* The widest CI goes to Long Beach, CA
* The narrowest CI goes to Chicago, IL

## Problem 3

Import the data, load and clean the data for regression analysis.

```{r}
weight_df = 
  read_csv('./data/birthweight.csv') %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    mrace = as.factor(mrace),
    malform = as.factor(malform)
    ) %>% 
  drop_na()
```

Propose a regression model for birthweight, and the modeling process: I make some hypothesis about these factors to effect the birth weight:

* fincome (family monthly income): the family richer, more nutrition the mothers get;
* malform (presence of malformations): the presence of malformations tend to effect the birth weight;
* pnumlbw (previous number of low birth weight babies): the more previous number of low birth weight babies, the larger probability this baby present the low birth weight;
* smoken (average number of cigarettes smoked per day during pregnancy): smoking during pregnancy tend to effect the birth weigh.

```{r}
bw_reg_0 = lm(bwt ~ fincome + malform + pnumlbw + smoken, data = weight_df)
```

Show a plot of model residuals against fitted values â€“ use add_predictions and add_residuals in making this plot.

```{r fig.width=6, fig.height=6, warning = FALSE}
weight_df %>% 
  add_predictions(bw_reg_0) %>% 
  add_residuals(bw_reg_0) %>% 
  ggplot(aes(x = resid, y = pred)) +
  geom_point(alpha = .5) +
  labs(
    title = 'Model Residuals against Fitted Values',
    x = 'Residuals',
    y = 'Fitted Values',
    caption = 'UNI: ax2173'
  )
```

Construct two other models to make some comparisons between them.

```{r}
bw_reg_1 = lm(bwt ~ blength + gaweeks, data = weight_df)
bw_reg_2 = lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = weight_df)
```

Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

```{r fig.width=6, fig.height=6, warning = FALSE}
weight_df_comparison = 
  weight_df %>% 
  crossv_mc(100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>% 
  mutate(
    model_0 = map(.x = train, ~lm(bwt ~ fincome + malform + pnumlbw + smoken, data = .x)),
    model_1 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_2 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x))
  ) %>% 
  mutate(
    rmse_0 = map2_dbl(.x = model_0, .y = test, ~rmse(model = .x, data = .y)),
    rmse_1 = map2_dbl(.x = model_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(.x = model_2, .y = test, ~rmse(model = .x, data = .y))
  )

weight_df_comparison %>% 
  select(starts_with('rmse')) %>% 
  pivot_longer(
    everything(),
    names_to = 'model',
    values_to = 'rmse',
    names_prefix = 'rmse_'
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  labs(
    title = 'Comparison between Three Models',
    x = 'Model',
    y = 'rmse',
    caption = 'UNI: ax2173'
  )
```

From the chart, we can get the conclusion that my original model performs the worst, and the third model (model_2) performs the best.